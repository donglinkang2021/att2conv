# IDEA

早上刚起床没多久在寝室想到一个有趣的问题，考完试之后可以再思考一下，走路来图书馆的时候一直在琢磨这个事情，就是：

卷积操作其实也是一种相似度计算。

是的，这里为了论证这个观点，自己首先想到的是模板匹配问题。模板匹配本身就是用一块小模板去匹配原图像中的各个区域，然后计算相似度，最后获得相似度最大的地方，从而找到了最像的区域。

好转变一下，假设我们的卷积核，这里直接从原图像中复制一个3x3区域的值给到卷积核，那么这个卷积核和原图像经过一轮卷积之后，原来的位置的那个点乘求和的值肯定是相对较高的，因为各项是直接平方都大于零，也就是说原来被复制的区域的相似度是较高的。

那么，来阐述一下卷积神经网络做分类任务的可解释性。

我们首先输入一张图像，由一个随机分布（高斯分布或者其它分布）的卷积核（模板）进行卷积操作（相似度计算工作），最后得到一张卷积之后的图像，我们称为特征图（这里不妨称为相似度图，由模板对其余各个位置计算相似度值的图），然后进行relu（保留正的相似度，因为我们只想要相似度大的地方作为模板），得到激活后的特征图（得到只有正相似度和零的相似度图），如果是深层卷积那么我们就在特征图的基础上进一步卷积（也即用相似度图的模板进一步去匹配相似度图），找到相似度更大的地方；卷积说完了说池化（pooling觉得翻译成池化本来就是用来忽悠人的，应该翻译成聚集才对），我们从相似度图中逐个区域中挑选一个相似度最大的值保留；不断重复上述操作之后，我们得到了很多张模板对应的相似度（对没错，就是一个模板一个相似度），然后用各个模板对应的相似度去进行线性变换成类别个数的相似度；

说完了前向传播说反向传播，先看最后的classifier，假设线性层输入相似度（各个模板对应的相似度）为定值，那么线性层的参数无非就是通过一批批图片的学习，自适应调整各个模板相似度的权重对于某一类的贡献权重，说白了回归问题，即**调整各个模板相似度对于类别相似度的贡献参数**；改完了线性层的参数，接着我们就可以得到各个模板对应的相似度误差loss；接着我们根据这个各个模板对应的相似度误差（有大有小，对类别相似度贡献度大的，误差传回来的时候当然也就大），来更新卷积层（各个模板）的参数，通过反馈回来的类别相似度信息，我们调整各个模板中的各个像素的值，使之向*模板空间*中的能获得较高相似度的位置靠拢（想象模板也是一个向量，此时误差大的模板相似度对应的模板在这个空间中就*走*的更快），最后得到一系列模板，有的模板几乎没有作用（它对原图像处理后的相似度对类别相似度的贡献度几乎为零），有的模板则是比较大的（它对原图像处理后的相似度对类别贡献度的相对较高）

此时可以想到几个可以进一步研究的方向，之后考完试可以想想，挺有意思的。

- 将贡献度较低的那一堆模板删掉，可不可以做轻量化的部署
    - 将大模型部署在小的移动端上
    - 让模型不那么*大*
    - 本来模型训练的时候希望大一点因为希望可以多个随机模板多种可能性探索
    - 但推理的时候为了节省成本是否可以对模板（卷积核）只保留必要的参数呢，把剩余不必要的参数拿掉 1+(3213-3213)+1=2
- 可以理解了卷积既然也是相似度计算，那么是否可以把注意力机制也改成卷积的版本
	- ViT无非就是将原图像拆分成各个区域的模板，得到模板序列，然后对模板序列和模板序列之间进行相似度计算
	- 既然如此为什么不让卷积核中的参数一开始就等于该区域的值，（模板的值一开始就赋予区域的值，而不是赋予随机值）
		- 再将卷积操作中的stride设置为模板的大小，不fit就padding就可以了
		- 然后对原图像进行卷积就完事了，得到的张量进行维度调整
	- 举个例子，原图像(192,192)划分成9个(64,64)的区域，每个区域的值直接作为模板的值
		- 开始卷积kernel_size = (64,64) padding = (0,0) stride = (64,64) 通道为9此时
		- 输出 (3,3,9) X.reshape(-1,9) 得到注意力图 yep
		- 考完试一定要试一下代码实现
- 使用卷积替换注意力操作，记得很多人发论文都阐述了这个观点，卷积并不比transformer结构差的啥啥啥
		
让计算变得高效，不让怎么计算机科学与技术呢😛😛😛

---- 2024.1.4